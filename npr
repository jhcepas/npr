#!/usr/bin/env python
import os
import imp
import logging
import numpy
from hashlib import md5

from argparse import ArgumentParser, RawDescriptionHelpFormatter
from configobj import ConfigObj, flatten_errors
import validate

from utils import SeqGroup, AA, NT
from errors import ConfigError, DataError

from master_task import Task
from interface import app_wrapper
from scheduler import schedule
import db

try:
    module_path = os.path.split(__file__)[0]
    __VERSION__ = open(os.path.join(module_path, "VERSION")).read().strip()
except: 
    __VERSION__ = "unknown"

try:
    module_path = os.path.split(__file__)[0]
    __DATE__ = open(os.path.join(module_path, "DATE")).read().strip()
except: 
    __DATE__ = "unknown"

__DESCRIPTION__ = """ 
--------------------------------------------------------------------------------
                 Nested Phylogenetic Reconstruction program.  
                          NPR-0.1%s(alpha), %s.

      @@2:NPR@@1: allows to reconstruct large phylogenies by means of
      an iterative strategy that provides scalable resolution and
      continuous update of tree topologies. In NPR, all internal nodes
      in a tree are re-evaluated to optimize and fine tune the
      parameters of phylogenetic inference.

      If you use this program for published work, please cite:

       Jaime Huerta-Cepas and Toni Gabaldon. Nested Phylogenetic
       Reconstruction. XXX-XX. 2012.

      Contact: jhuerta [at] crg.es, tgabaldon [at] crg.es
--------------------------------------------------------------------------------
""" %(__VERSION__, __DATE__)

def is_boolean_list(value, min=None, max=None):
    untyped_value = validate.is_list(value, min, max)
    typed_value = []
    for v in untyped_value: 
        try:
            typed_value.append(validate.is_boolean(v))
        except TypeError: 
            VdtTypeError(v)
    return typed_value

def is_positive_integer_list(value, min=None, max=None):
    untyped_value = validate.is_list(value, min, max)
    typed_value = []
    for v in untyped_value: 
        try:
            typed_value.append(validate.is_integer(v))
        except TypeError: 
            VdtTypeError(v)
        else:
            if v < 0: 
                VdtTypeError(v)
    return typed_value

def main(args):
    log = logging.getLogger("main")
    print __DESCRIPTION__

    configspec = ConfigObj("specs", 
                           list_values=False, _inspec=True)
    config = ConfigObj("config", configspec=configspec, list_values=True)
    custom_types = {"boolean_list": is_boolean_list, 
                    "positive_integer_list": is_positive_integer_list, 
                    }
    val = validate.Validator(custom_types)
    check = config.validate(val)
    if not check:
        print flatten_errors(config, check)
        raise ConfigError("Bad config file")

    # Check for unique max_seq config values
    if len(config["main"]["npr_max_seqs"]) != \
            len(set(config["main"]["npr_max_seqs"])):
        raise ConfigError("Duplicated entries in 'npr_max_seqs'.")

    # Check for unique max_seq config values
    if config["main"]["npr_max_seqs"] != \
            sorted(config["main"]["npr_max_seqs"]):
        raise ConfigError("'npr_max_seqs' values must be in ascending order.")

    # Check that fields are filled for all max_seq values
    conf_keys = [v for v in config["main"] if v.startswith("npr_")]
    if len(set([len(config["main"][v]) for v in conf_keys])) != 1:
        raise ConfigError("Error reading config file:"
                         " Unequal length of config table")
    
    #base_dir = os.path.abspath(config["main"]["basedir"])
    base_dir = os.path.abspath(args.outdir)
    gallery_dir = os.path.join(base_dir, "gallery")
    snapshots_dir = os.path.join(base_dir, "tree_snapshots")
    sge_dir = os.path.join(base_dir, "sge_jobs")
    config["main"]["sge_dir"] = sge_dir
    config["main"]["gallery_dir"] = gallery_dir
    config["main"]["snapshots_dir"] = snapshots_dir
    try:
        os.makedirs(gallery_dir)
        os.makedirs(snapshots_dir)
        os.makedirs(sge_dir)
    except OSError:
        pass

    config["main"]["basedir"] = base_dir
    Task.global_config["basedir"] = base_dir

    config["main"]["_max_cores"] = args.maxcores

    # Initialize db
    db.init_db(os.path.join(base_dir, "tasks.sqlite"))
    
    # Load pipeline
    pipeline_module = config["main"]["pipeline"]
    if os.path.isfile(pipeline_module):
        template = imp.load_module("__main__.standard1", open(pipeline_module),
                                   pipeline_module, ["py", "r", imp.PY_SOURCE])
    else:
        imp.find_module("standard1", __path__)

    # check nt_seed and aa_seed. Do they contain the same seqs?
    # format? names?
    visited_seqs = set()
    seed_files = {}
    seq2aalength = {}
    seq2ntlength = {}
    for label, seq_file, seq2length in [["aa_seed", args.aa_seed_file, seq2aalength],
                                        ["nt_seed", args.nt_seed_file, seq2ntlength]]:
        if seq_file: 
            SEQS = SeqGroup(seq_file)
            # Loads seq lengths
            for seqname, seq, comment in SEQS.iter_entries():
                seq2length[seqname] = len(seq)
                if label == "nt_seed" and set(seq)-NT:
                    error = "Unknown symbols [%s] in sequence [%s] of file [%s]" %\
                        (''.join(set(seq)-NT), seqname, seq_file)
                    raise DataError(error)
                elif label == "aa_seed" and set(seq)-AA:
                    error = "Unknown symbols [%s] in sequence[%s] of file [%s]" %\
                        (''.join(set(seq)-AA), seqname, seq_file)
                    raise DataError(error)

            id2name = {}
            for i,n in SEQS.id2name.iteritems():
                if args.seq_rename:
                    # This is a bit tricky. I want to generate 10 char
                    # unique names that are identical for identical
                    # original names. Hash functions cannot generate
                    # less than 16 bits strings, so I will trust in
                    # the first 10 chars. It is very unlikely to get a
                    # collision even in large sets (million of
                    # names.), but in such a case, I will rise an
                    # error.
                    name = md5(n).hexdigest()[:10]
                    id2name[name] = SEQS.id2name[i]
                    SEQS.id2name[i] = name

                elif len(n)>10: 
                    SEQS.id2name[i] = n[:10]
                    log.warning("sequence name %s was truncated to 10"
                                " chars: %s " %(n, n[:10]))

            values = SEQS.id2name.values()
            if len(values) != len(set(values)):
                if args.seq_rename:
                    raise DataError("Although collisions in the hash function"
                                    " used to generate unique sequence names"
                                    " are very unlikely, you found an exception!."
                                    " You will have to change seq names manually.")
                else:
                    raise DataError("Duplicated sequence names, execution"
                                    " aborted. Correct manually or set"
                                    " automatic sequence renaming with"
                                    " --seq_rename flag.")

            if visited_seqs and set(values) != visited_seqs:
                raise DataError("Sequence names do not match between aa and"
                                " nt files.")
            visited_seqs.update(values)
            fullpath = os.path.join(base_dir, label+".fasta")
            seed_files[label] = fullpath
            SEQS.write(outfile=fullpath)

    if id2name: 
        id_conversion_file = os.path.join(base_dir, "id_conversion.txt")
        CONV = open(id_conversion_file, "w")
        CONV.write('\n'.join(["%s\t%s" %(i,v) 
                              for i,v in id2name.iteritems()]))
        CONV.close()

    config["main"]["aa_seed"] =  seed_files.get("aa_seed", None)
    config["main"]["nt_seed"] =  seed_files.get("nt_seed", None)

    if seq2ntlength and seq2aalength:
        for seqname, length in seq2aalength.iteritems():
            try:
                if length != seq2ntlength[seqname]/3.0:
                    raise DataError("The length of [%s] CDS does not match"
                                     "with the protein sequence." %seqname)
            except KeyError:
                raise DataError("aa and nt files do not contain the same"
                               "sequence identifiers.")

    # Sequence lengths analysis
    if seq2aalength:
        all_len = seq2aalength.values()
    else:
        all_len = seq2ntlength.values()
   
    max_len = numpy.max(all_len)
    min_len = numpy.min(all_len)
    mean_len = numpy.mean(all_len)
    std_len = numpy.std(all_len)
    outliers = []
    for v in all_len:
        if abs(mean_len - v) >  (2 * std_len):
            outliers.append(v)
    log.info("Max sequence length:  %d" %max_len)
    log.info("Min sequence length:  %d" %min_len)
    log.info("Mean sequence length: %d +- %0.1f " %(mean_len, std_len))
    if outliers:
        log.warning("%d sequence lengths look like outliers" %len(outliers))

    # how task will be executed
    if args.execute:
        execution ="insitu"
    elif args.sge_execute:
        execution = "sge"
    else:
        execution = None

    # Scheduling starts here
    schedule(config, template.pipeline, args.schedule_time, 
             execution, args.retry)

if __name__ == "__main__":
    parser = ArgumentParser(description=__DESCRIPTION__, 
                            formatter_class=RawDescriptionHelpFormatter)
    # name or flags - Either a name or a list of option strings, e.g. foo or -f, --foo.
    # action - The basic type of action to be taken when this argument is encountered at the command line. (store, store_const, store_true, store_false, append, append_const, version)
    # nargs - The number of command-line arguments that should be consumed. (N, ? (one or default), * (all 1 or more), + (more than 1) )
    # const - A constant value required by some action and nargs selections. 
    # default - The value produced if the argument is absent from the command line.
    # type - The type to which the command-line argument should be converted.
    # choices - A container of the allowable values for the argument.
    # required - Whether or not the command-line option may be omitted (optionals only).
    # help - A brief description of what the argument does.
    # metavar - A name for the argument in usage messages.
    # dest - The name of the attribute to be added to the object returned by parse_args().

    parser.add_argument("-c", "--config", dest="configfile", 
                        type=str, required=True, 
                        help="""A valid config file to execute the pipeline""")
    
    
    # Output data related flags
    parser.add_argument("-o", "--outdir", dest="outdir", 
                        type=str, required=True, 
                        help="""Output directory for results.""")

    # Input data related flags
    parser.add_argument("-a", "--aa-seed-file", dest="aa_seed_file", 
                        type=str, 
                        help="Initial multi sequence file with"
                        " protein sequences")

    parser.add_argument("-n", "--nt-seed-file", dest="nt_seed_file", 
                        type=str, 
                        help="Initial multi sequence file with"
                        " nucleotide sequences")

    parser.add_argument("--seq_rename", dest="seq_rename", 
                        action="store_true",
                        help="If used, seq names are internally converted"
                        " to safe and unique 10 char identifiers.")

    # Task execution related flags
    parser.add_argument("-r", "--retry-error-jobs", dest="retry", 
                        action="store_true",
                        help="""Try to relaunch jobs marked as error """)
    
    exec_group = parser.add_mutually_exclusive_group()
    exec_group.add_argument("-x", "--insitu-execution", dest="execute", 
                        action="store_true",
                        help="Jobs are launched in the same machine"
                        " as in the program is called.")

    exec_group.add_argument("-sge", dest="sge_execute",
                        action="store_true", help="Jobs will be"
                        " launched using the Sun Grid Engine"
                        " queue system.")
    
    parser.add_argument("-t", "--schedule-time", dest="schedule_time", 
                        type=float, default=5.0,
                        help="""Schedule time in seconds. """)

    parser.add_argument("-m", "--maxcores", dest="maxcores", type=int,
                        default=1, help="Maximum number of CPU cores"
                        " available in the execution hosts. If higher"
                        " than 1, tasks with multi-threading"
                        " capabilities will be set appropriately.")

    # Interface related flags
    parser.add_argument("-u", "--ui", dest="enable_ui",
                        action="store_true", help="When used, a color"
                        " based interface is launched to monitor NPR"
                        " processes. This feature requires NCURSES"
                        " libraries installed in your system.")

    parser.add_argument("-v", "--verbosity", dest="verbosity",
                        default = 1, type=int, choices=[0,1,2,3,4,5],
                        help="0=very quiet, 4=very verbose. 5=debug")
    
    args = parser.parse_args()
   
    # Start the application
    app_wrapper(main, args)


