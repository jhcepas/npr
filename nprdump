#!/usr/bin/env python
import sys
import os
import cPickle
import shutil

# This avoids installing nprlib module. npr script will find it in the
# same directory in which it is
NPRPATH = os.path.split(os.path.realpath(__file__))[0]
sys.path.insert(0, NPRPATH)

from nprlib.argparse import ArgumentParser, RawDescriptionHelpFormatter
from nprlib import db
from nprlib.errors import DataError, ConfigError
from nprlib.logger import get_main_log
from nprlib.utils import Tree, pjoin, generate_id, get_latest_nprdp, symlink

def iter_prepostorder(tree):
    finished_nodes = set()
    node = tree
    while node:
        if node.children:
            next_node = None
            for ch in node.children:
                if ch not in finished_nodes:
                    next_node = ch
                    yield next_node, "pre"
                    break
            if not next_node:
                finished_nodes.add(node)
                yield node, "post"
                node = node.up
            else:
                node = next_node
        else:
            finished_nodes.add(node)
            node = node.up
           

def walk(runid, outdir):
    log.info("Reading nodes from database...")
    thread_fname =  pjoin(outdir, "threads")
    THREAD = open(thread_fname, "w")
    task_nodes = db.get_runid_nodes(runid)
    task_nodes.reverse()
    clade2tree = {}
    for cladeid, packtree, size in task_nodes:
        if packtree:
            clade2tree[cladeid] = [packtree, size]
    
    node = main_tree = db.decode(task_nodes[-1][1])
    visited_nodes = set()
    dumpiter = 0
    main_tree.add_features(dumpiter=dumpiter)
    dump(dumpiter, main_tree, main_tree, outdir)
    #print main_tree.get_ascii(attributes=["dumpiter", "name"])
    iter_string = [0]
    while node:
        child_node = None
        for ch in node.children:
            if ch not in visited_nodes:
                child_node = ch
                break
        if child_node:
            visited_nodes.add(child_node)
            if child_node.cladeid in clade2tree:
                new_thread = True
                packtree, size  = clade2tree[child_node.cladeid]
                dumpiter += 1
                iter_string.append(dumpiter)
                log.info("Dumping iteration %s, size of optimized node: %d. %s", dumpiter, size, iter_string)
                task_tree = db.decode(packtree)
                orig_node = child_node
                # exchange orig node by optimized one
                orig_node.detach() 
                node.add_child(task_tree)
                task_tree.orig_node = orig_node
                child_node = task_tree
                child_node.add_features(dumpiter=dumpiter)
                dump(dumpiter, child_node, main_tree, outdir)

                #print main_tree.get_ascii(attributes=["dumpiter", "name"])
                #raw_input()
            node = child_node
        else:
            parent = node.up
            if hasattr(node, "orig_node"):
                if new_thread:
                    print >>THREAD, ','.join(map(lambda x: "%05d.nwx" %x, iter_string))
                    THREAD.flush()
                    new_thread = False
                log.info("Detaching cladeid %s", node.cladeid)
                node.detach()
                for ch in node.children:
                    visited_nodes.discard(ch)
                parent.add_child(node.orig_node)
                node.orig_node = None
                del clade2tree[node.cladeid]
                iter_string.pop(-1)
            node = parent
    THREAD.close()
    log.info("Threads written in %s", thread_fname)

def dump(dumpiter, target, tree, outdir):
    # Restore original gene names
    for leaf in tree.iter_leaves():
        leaf.add_features(safename=leaf.name)
        leaf.name = leaf.realname

    base_fname = pjoin(outdir, "%05d" %dumpiter)
    OUT = open(base_fname+".info", "w")
    for k in sorted(target.features):
        print >>OUT, "\t".join([k, str(getattr(target, k))])
    OUT.close()
    tree.write(features=[], outfile=base_fname+".nwx")
    tree.write(outfile=base_fname+".nw")

            
def assembly_tree(runid, outdir):
    log.info("Reading nodes from database...")
    task_nodes = db.get_runid_nodes(runid)
    task_nodes.reverse()

    clade_tree = None
    clade_content = None
    if args.cladeid:
        for cladeid, packtree, size in task_nodes:
            if cladeid == args.cladeid:
                clade_tree = db.decode(packtree)
                clade_content = set(clade_tree.get_leaf_names())
        log.info("Tracking clade %s of size %d", args.cladeid, len(clade_content))
    
    main_tree = None
    iternumber = 1
    log.info("Dumping iterations...")
    while task_nodes:
        cladeid, packtree, size = task_nodes.pop(-1)
        if cladeid == args.cladeid:
            tree = clade_tree
            log.info("Cladeid reached!. Now descending from target node!")
            #task_nodes = [] # do not continue dumping iterations
        elif packtree:
            tree = db.decode(packtree)
        else:
            #print "No tree?", cladeid
            continue
                    
        if clade_content:
            if not (clade_content & set(tree.get_leaf_names())):
                log.info("Skipping optimized node in a different branch (size: %d).", size)
                continue

        # print tree.dist
        # Restore original gene names
        for leaf in tree.iter_leaves():
            leaf.add_features(safename=leaf.name)
            leaf.name = leaf.realname
            
        if main_tree:
            prev_tree = main_tree.copy()
            # substitute node in main tree by the optimized one
            target_node = main_tree.search_nodes(cladeid=cladeid)[0]
            target_node.up.add_child(tree)
            target_node.detach()
            print "RF with prev tree:", main_tree.robinson_foulds(prev_tree)[:2], len(tree)
            if len(target_node)!= len(tree):
                print "cladeids"
                print "searched", cladeid
                print "recomputed", len(target_node), generate_id(target_node.get_leaf_names())

                print iternumber, len(main_tree), "expected size", len(tree), "observed", len(target_node)
                __targets, __outs = db.print_node_by_clade(runid, cladeid)
                print "recomputed from DB", len(__targets), generate_id(__targets)
                raw_input()
        else:
            main_tree = tree

        iter_name = "Iter_%04d_%dseqs" %(iternumber, size)
        iter_outdir = pjoin(outdir, iter_name)
        try:
            os.mkdir(iter_outdir)
        except OSError:
            pass
        
        base_fname = pjoin(iter_outdir, "%04d" %iternumber)
        tree.add_features(iternumber=iternumber)
        OUT = open(base_fname+".info", "w")
        for keyname in sorted(tree.features):
            print >>OUT, "\t".join([keyname, str(getattr(tree, keyname))])
            # create symlinks relevant data
            if keyname.endswith("_path"):
                try:
                    os.remove(pjoin(iter_outdir, keyname))
                except OSError:
                    pass
                try: # This will not work on windows
                    os.symlink(os.path.abspath(pjoin(BASE_DIR, getattr(tree, keyname))),
                               pjoin(iter_outdir, keyname))
                except OSError:
                    pass
                              
        OUT.close()
        main_tree.write(outfile=base_fname+".nw")
        main_tree.write(features=[], outfile=base_fname+".nwx")
        if REF_TREE:
            cmp_tree = main_tree.copy("newick") # do not change main tree topology
            if len(REF_OUT) == 1:
                cmp_tree.set_outgroup(REF_OUT[0])
            else:
                common = cmp_tree.get_common_ancestor(REF_OUT)
                cmp_tree.set_outgroup(common)
            dist = REF_TREE.robinson_foulds(cmp_tree)[:2]
            print '\t'.join(map(str, ["TAB", runname, size, iternumber, dist[0], dist[1]]))
            log.info("Dumped iteration % 3d, size of optimized node: % 4d (dist to final tree=%s)", iternumber, size, dist)
        else: 
            log.info("Dumped iteration %s, size of optimized node: %d", iternumber, size)            
        iternumber += 1
    rel_path = base_fname.replace(outdir, "")
    rel_path = "./" + rel_path.lstrip("/")
    symlink(rel_path+".nw", pjoin(outdir, "last_iter.nw"))
    symlink(rel_path+".nwx", pjoin(outdir, "last_iter.nwx"))
    symlink(rel_path+".info", pjoin(outdir, "last_iter.info"))
    
   
__DESCRIPTION__ = "Dump each iteration (tree and info) of a NPR execution."
       
if __name__ == "__main__":
    log = get_main_log(sys.stdout)
    
    parser = ArgumentParser(description=__DESCRIPTION__, 
                            formatter_class=RawDescriptionHelpFormatter)
 
    parser.add_argument('nprdir', metavar='npr_base_dir', type=str, nargs=1,
                   help='path to an NPR execution directory')

    parser.add_argument("-r", dest="runid", 
                        type=str,
                        help="""RunID""")

    parser.add_argument("-o", dest="outdir", 
                        type=str,
                        help="""Where iteration snapshots will be saved""")


    dumptype = parser.add_mutually_exclusive_group()
    dumptype.title = "How iterations should be assembled"
    dumptype.required = True
    dumptype.add_argument("--cladeid", dest="cladeid", 
                        type=str,
                        help="""Dump only iteration involving a given clade""")
    
    dumptype.add_argument("-a",  dest="assembly", 
                        action="store_true",
                        help="""Assembly final tree node by node, from larger to smaller optimized partitions.""")

    dumptype.add_argument("-b",  dest="branch_assembly", 
                        action="store_true",
                        help="""Per branch assembly of the tree. Note that optimized partitions of independent branches are not combined. """)

    parser.add_argument("--root", dest="root", type=str,
                        help="dumped trees are rooted to the           "
                        "provided sequence/species name. You can refer " 
                        "to common ancestor nodes by providing several " 
                        "species names: i.e. --root human,mouse ")

    parser.add_argument("-c",  dest="config_name", 
                        type=str,
                        help="""computes only for this thread name""")
   
    parser.add_argument("--ref", dest="reftree", type=str,
                        help="Compare topology of iteration trees with"
                        " a reference topology")
    
    args = parser.parse_args()
        
    args = parser.parse_args()
    BASE_DIR = os.path.abspath(args.nprdir[0])
    if not os.path.isdir(BASE_DIR):
        raise ConfigError("NPR dir [%s] not found." %BASE_DIR)
    
    last_db = get_latest_nprdp(BASE_DIR)
    # make a temporal copy of DB to avoid interferences with running
    # jobs
    if not last_db or not os.path.exists(last_db):
        raise ConfigError("[%s] does not contain NPR data." %last_db)
    shutil.copy(last_db, last_db+".nprdump.tmp")
    DB_FILE = pjoin(BASE_DIR, last_db+".nprdump.tmp")

    if not args.runid:
        RUNID_NAME = {}
        if not args.runid:
            for fname in os.listdir(BASE_DIR):
                if args.config_name and fname != args.config_name:
                    continue
                runid_file = pjoin(BASE_DIR, fname, "runid")
                if os.path.exists(runid_file):
                    runid, runid_date = open(runid_file, "rU").readlines()[-1].split("\t")
                    RUNID_NAME[runid] = fname
        else:
            RUNID_NAME[args.runid] = "User_selected"
            runid_date = "?"
        # lines = open(os.path.join(BASE_DIR, "runid"), "rU").readlines()
        # selected_runid = lines[-1]
        # print ''.join(lines)
        # print "** Selected **", selected_runid
        # args.runid = selected_runid.split("\t")[0].strip()

    if args.root:
        REF_OUT = args.root.split(",")

    db.connect_nprdb(DB_FILE)
    for runid, runname in RUNID_NAME.iteritems():
        if args.cladeid: 
            file_label = "nprdump_clusterid_%s_runid_%s_%s" %(args.cladeid, runid[:8], runname)
        elif args.assembly:
            file_label = "nprdump_assembly_runid_%s_%s" %(runid[:8], runname)
        elif args.branch_assembly:
            file_label = "nprdump_branch_assembly_runid_%s_%s" %(runid[:8], runname)

        if not args.outdir: 
            outdir = os.path.join(BASE_DIR, runname, file_label)
        else:
            outdir = os.path.join(args.outdir, runname, file_label)

        log.info("Output directory: %s", outdir)
        try:
            os.mkdir(outdir)
        except OSError, e:
            log.warning(e)
        
        if args.assembly:
            final_tree_path = pjoin(BASE_DIR, runname, "final_tree.nw")
            if not args.reftree and os.path.exists(final_tree_path):
                REF_TREE = Tree(final_tree_path)
                if not args.root: 
                    REF_OUT = [REF_TREE.get_leaf_names()[0]]
                if len(REF_OUT) == 1:
                    REF_TREE.set_outgroup(REF_OUT[0])
                else:
                    common = REF_TREE.get_common_ancestor(REF_OUT)
                    REF_TREE.set_outgroup(common)
            elif args.reftree:
                REF_TREE = Tree(args.reftree)
                if not args.root: 
                    REF_OUT = [REF_TREE.get_leaf_names()[0]]
                    
                    if len(REF_OUT) == 1:
                        REF_TREE.set_outgroup(REF_OUT[0])
                    else:
                        common = REF_TREE.get_common_ancestor(REF_OUT)
                        REF_TREE.set_outgroup(common)
            else:
                REF_TREE = None
            assembly_tree(runid, outdir)

        elif args.branch_assembly:
            walk(runid, outdir)       
        print "\nResults written in ", outdir
